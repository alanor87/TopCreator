
Процесс створення додатку :

  

- створення нового проекту nodeJS :

``` npm init -y ```

 - встановлення необхідного стеку бібліотек :
   ```npm i dotenv express mongoose```
   
- ініціалізація  Typescript (встановлений глобально):
  ``tsc --init``
  
- встановлення типів як залежностей розробки :
  ``` npm i @faker-js/faker @types/express @types/mongodb ```
  
- створення команди скріпта транспіляції та запуску программи в package.json:
  ```"start": "tsc && node ./dist/index.js"```
 -  створення .env 
- створення файлової структури проекта

Принцип роботи программи :
  При запуску программи через команду npm start запускається підключення до бази данних. При успішному підключенні запускається сервер express та механізм генерації фейкових данних, а також механізм моніторингу змін,  дуплікації та анонімізації данних клієнтів. Моніторинг реалізований через доступний в mongoDB функціонал  Change Streams, що дозволяє отримувати данні по змінам в зазначених коллекціях данних. Відповідно до ТЗ, ми "слухаємо" два види подій - створення нових записів та зміну існуючих. Дублікати нових записів створюються з тим самим id, що і в записів оригінальних. При зміні оригінального запису відбувається повторне хешування змінених полів відповідного анонімізованого дублікату. Алгоритм хешування модернізований в відповідності до ТЗ - хешована версія поля має фіксовану довжину 8 символів, цифри, upper та lower case букви. Анонімізовані данні детерміновані, тобто легко встановити відповідність між вихідними та вхідними данними через повторне хешування оригіналу.
 
  Загальна картина виглядає наступним чином : программа сама генерує данні та сама виконує всі маніпуляції з данними відповідно до ТЗ. В ТЗ не було вказано створення api для серверу, тобто не передбачається, що данні будуть надходити "ззовні". При вказаних в ТЗ навантаженнях (1-10 записів кожні 200 мсек) программа показала стабільну роботу свого функціоналу при взаємодії з БД на https://cloud.mongodb.com/
  
  Программа в данному вигляді є концептом. При реалізаціі подібного функціоналу для production я б додав наступне :
   - більш детальна та гранульована обробка помилок.
   - механізм безперебійної роботи пайплайну створення дублікатів записів користувачів на випадок великих навантаженнь та проблем із передачею данних в мережі : ми маємо бути впевнені, що кожному оригінальному запису відповідає анонімозований. Механізм би передбачав повторні спроби створення дублікатів записів при невдалих попередніх спробах створення.
   - в залежності від контексту використання данного механізма, можливо, більш раціональним рішенням було би одночасне створення оригінального та анонімізованного записів замість "моніторинга" оригінальної коллекції документів.
   
   
   Хочу подякувати команді TopCreator за цікаве технічне завдання!